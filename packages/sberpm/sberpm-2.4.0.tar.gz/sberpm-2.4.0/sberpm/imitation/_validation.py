from functools import partialmethod
from itertools import product
from multiprocessing import Pool, cpu_count

from numpy import abs as abs_
from numpy import zeros
from pandas import DataFrame
from scipy.optimize import linear_sum_assignment

from tqdm import tqdm

# disable tqdm progress
tqdm.__init__ = partialmethod(tqdm.__init__, disable=False)


def damerau_levenshtein_distance(s1, s2):
    """
    Calculates Damerau–Levenshtein distance between two sequences of activities (event traces).

    Parameters
    ----------
    s1: array-like of str
        First sequence of activities.
    s2: array-like of str
        Second sequence of activities.

    Returns
    -------
    dl_dist: float
        Damerau–Levenshtein distance.
    """
    dist = {}
    len1 = len(s1)
    len2 = len(s2)
    for i in range(-1, len1 + 1):
        dist[(i, -1)] = i + 1

    for j in range(-1, len2 + 1):
        dist[(-1, j)] = j + 1

    for i, j in product(range(len1), range(len2)):
        cost = 0 if s1[i] == s2[j] else 1
        dist[(i, j)] = min(
            dist[(i - 1, j)] + 1,  # deletion
            dist[(i, j - 1)] + 1,  # insertion
            dist[(i - 1, j - 1)] + cost,  # substitution
        )
        if i > 1 and j > 1 and s1[i] == s2[j - 1] and s1[i - 1] == s2[j]:
            dist[(i, j)] = min(dist[(i, j)], dist[i - 2, j - 2] + 1)  # transposition
    return dist[len1 - 1, len2 - 1]


def modified_damerau_levenshtein_distance(s1, s2, t1, t2):
    """
    Calculates modified Damerau–Levenshtein distance between two sequences of activities (event traces).
    Modification is in taking into consideration the execution time of activities.

    Parameters
    ----------
    s1: array-like of str
        First sequence of activities.
    s2: array-like of str
        Second sequence of activities.

    t1: array-like of float
        Execution time sequence that corresponds to the first sequence of activities.

    t2: array-like of float
        Execution time sequence that corresponds to the second sequence of activities.

    Returns
    -------
    mod_dl_dist: float
        Modified Damerau–Levenshtein distance.
    """
    dist = {}
    len1 = len(s1)
    len2 = len(s2)
    for i in range(-1, len1 + 1):
        dist[(i, -1)] = i + 1

    for j in range(-1, len2 + 1):
        dist[(-1, j)] = j + 1

    for i, j in product(range(len1), range(len2)):
        cost = abs_(t1[i] - t2[j]) if s1[i] == s2[j] else 1
        dist[(i, j)] = min(
            dist[(i - 1, j)] + 1,  # deletion
            dist[(i, j - 1)] + 1,  # insertion
            dist[(i - 1, j - 1)] + cost,  # substitution
        )
        if i > 1 and j > 1 and s1[i] == s2[j - 1] and s1[i - 1] == s2[j]:
            dist[(i, j)] = min(dist[(i, j)], dist[i - 2, j - 2] + 1)  # transposition
    return dist[len1 - 1, len2 - 1]


class SimilarityMetric:
    """
    Class that validates the simulation model by measuring the similarity between generated and original event logs
    using the modification of Damerau-Levenshtein distance.

    Parameters
    ----------
    simulation_data: pandas.DataFrame
        Event log generated by the simulation model.

    data_holder: sberpm.DataHolder
        Object that contains the original event log and names of its necessary columns (id, activity, timestamp, etc.).

    n_jobs: int or 'auto', default=1
        If int, number of processes that will be created to calculate the metric.
        If 'auto', number of processes will depend on the number of event traces in the original and
        generated logs (from 1 to number_of_logical_cpu / 2).

    Attributes
    ---------
    result: pandas.DataFrame
            Result of the calculation. Columns:
                'sim_id': id of the simulated trace,
                'sim_trace': simulated trace,
                'log_id': id of the most similar real trace,
                'sim_trace': real trace,
                'similarity_score': similarity score between simulated and most similar real traces.

    similarity: float
        Average similarity score of the real log and simulated data.


    Examples
    --------
    >>> from sberpm.imitation import Simulation
    >>> sim = Simulation(data_holder)
    >>> sim_data = sim.run(num_traces=800)
    >>> from sberpm.imitation import SimilarityMetric
    >>> sim_metric = SimilarityMetric(sim_data, data_holder)
    >>> print(sim_metric.similarity)
    """

    def __init__(self, simulation_data, data_holder, n_jobs=1):
        self._holder = data_holder
        self._holder.check_or_calc_duration()
        self._duration_column_norm = self._holder.duration_column + "_norm"
        self._log_data = self._time_scaling(
            self._holder.data[[self._holder.id_column, self._holder.activity_column, self._holder.duration_column]]
        )
        self._simulation_data = self._time_scaling(simulation_data)
        log_data_grouped, simulation_data_grouped = self._prepare_data()
        self.result = self._calc_similarity_metric(log_data_grouped, simulation_data_grouped, n_jobs)
        self.similarity = self.result["similarity_score"].mean()

    def _time_scaling(self, data):
        """
        Creates new column with normalized time durations for each activity.

        Parameters
        ----------
        data: pandas.DataFrame
            Event log data with the same id, activity and duration columns as in data_holder.

        Returns
        -------
        new_data: pandas.DataFrame
            Same data with new column of normalized time durations of activities.
        """
        new_data = data.copy()
        new_data[self._holder.duration_column].fillna(0.0, inplace=True)
        max_durations = new_data.groupby(self._holder.activity_column)[self._holder.duration_column].max()
        max_durations.loc[max_durations == 0] = 1  # so that there will not be division by zero
        new_data = new_data.join(max_durations, on=self._holder.activity_column, how="left", rsuffix="_max")
        new_data[self._duration_column_norm] = (
            new_data[self._holder.duration_column] / new_data[self._holder.duration_column + "_max"]
        )
        new_data.drop(self._holder.duration_column + "_max", axis=1, inplace=True)

        return new_data

    def _prepare_data(self):
        """
        Returns two dataframes (real and simulated one) with grouped data
        (activities and their time durations aggregated to arrays).

        Returns
        -------
        log_data: pandas.DataFrame
            Grouped data of the real event log.

        simulation_data: pandas.DataFrame
            Grouped data of the simulated event log.
        """
        log_data = (
            self._log_data.groupby(self._holder.id_column)
            .agg({self._holder.activity_column: tuple, self._duration_column_norm: tuple})
            .reset_index()
        )
        simulation_data = (
            self._simulation_data.groupby(self._holder.id_column)
            .agg({self._holder.activity_column: tuple, self._duration_column_norm: tuple})
            .reset_index()
        )
        return log_data, simulation_data

    # TODO refactor
    def _calc_similarity_metric(self, log_data, sim_data, n_jobs):
        """
        Parameters
        ----------
        log_data: pandas.DataFrame
            Grouped data of the real event log.

        sim_data: pandas.DataFrame
            Grouped data of the simulated event log.

        n_jobs: int or 'auto'
            If int, number of processes that will be created to calculate the metric.
            If 'auto', number of processes will depend on the number of event traces in the original and
            generated logs (from 1 to number_of_logical_cpu / 2).

        Returns
        -------
        result: pandas.DataFrame
            Result of the calculation. Columns:
                'sim_id': id of the simulated trace,
                'sim_trace': simulated trace,
                'log_id': id of the most similar real trace,
                'sim_trace': real trace,
                'similarity_score': similarity score between simulated and most similar real traces.
        """
        sim_len = len(sim_data)
        log_len = len(log_data)

        # Set proper n_jobs
        if n_jobs == "auto":
            n_jobs = 1 if sim_len * log_len < 300000 else cpu_count() // 2
        else:
            n_jobs = n_jobs if n_jobs > 0 else cpu_count() - n_jobs + 1

        if n_jobs == 1:
            cost_matrix, _ = self._calc_cost_matrix(sim_data, log_data, None)
        else:
            pool = Pool(n_jobs)
            cost_matrix = zeros(shape=(sim_len, log_len), dtype=float)
            if sim_len > log_len:
                result_objects = [
                    pool.apply_async(self._calc_cost_matrix, args=(sub_sim_data, log_data, sub_sim_data_indexes))
                    for sub_sim_data, sub_sim_data_indexes in generate_data_partitions(sim_data, log_data.shape[0])
                ]
                for r in tqdm(result_objects):
                    sub_cost_matrix, (ind1, ind2) = r.get()
                    cost_matrix[ind1:ind2, :] = sub_cost_matrix
            else:
                result_objects = [
                    pool.apply_async(self._calc_cost_matrix, args=(sim_data, sub_log_data, sub_log_data_indexes))
                    for sub_log_data, sub_log_data_indexes in generate_data_partitions(log_data, sim_data.shape[0])
                ]
                for r in tqdm(result_objects):
                    sub_cost_matrix, (ind1, ind2) = r.get()
                    cost_matrix[:, ind1:ind2] = sub_cost_matrix
            pool.close()
            pool.join()

        similarity_matrix = 1 - cost_matrix
        row_idx, col_idx = linear_sum_assignment(cost_matrix)  # row_idx - sim_data, col_idx - log_data
        sim_data.reset_index(drop=True, inplace=True)
        log_data.reset_index(drop=True, inplace=True)

        return DataFrame(
            {
                "sim_id": sim_data[self._holder.id_column].iloc[row_idx].reset_index(drop=True),
                "sim_trace": sim_data[self._holder.activity_column].iloc[row_idx].reset_index(drop=True),
                "log_id": log_data[self._holder.id_column].iloc[col_idx].reset_index(drop=True),
                "log_trace": log_data[self._holder.activity_column].iloc[col_idx].reset_index(drop=True),
                "similarity_score": similarity_matrix[row_idx, col_idx],
            }
        )

    def _calc_cost_matrix(self, df1, df2, indexes=None):
        """
        Calculates the distances between the event traces of the given dataframes.

        Parameters
        ----------
        df1: pandas.DataFrame
            Grouped data of the event log with activities and their time durations aggregated to arrays.

        df2: pandas.DataFrame
            Grouped data of the event log with activities and their time durations aggregated to arrays.

        indexes: tuple of (int, int), default=None
            Supposing there are two dataframes and one is bigger than the other, the bigger one is divided into parts.
            If one of the given dataframes is a part of a bigger one, these are its indexes in the bigger one.
            This parameter does not take part in calculation.

        Returns
        -------
        dist_matrix: np.array of float, shape=[df1.shape[0], df2.shape[0]]
            Matrix with the modified Damerau–Levenshtein distance between the event traces.

        indexes
        """
        dist_matrix = zeros(shape=(df1.shape[0], df2.shape[0]), dtype=float)
        for i, s1, t1 in tqdm(
            zip(
                range(df1.shape[0]),
                df1[self._holder.activity_column].values,
                df1[self._duration_column_norm].values,
            )
        ):
            for j, s2, t2 in zip(
                range(df2.shape[0]),
                df2[self._holder.activity_column].values,
                df2[self._duration_column_norm].values,
            ):
                max_len = max(len(s1), len(s2))
                dist_matrix[i, j] = modified_damerau_levenshtein_distance(s1, s2, t1, t2) / max_len
        return dist_matrix, indexes


def generate_data_partitions(bigger_df, smaller_df_length):
    """
    Supposing there are two dataframes and one is bigger than the other, the bigger one is divided into parts.
    Generates parts of the given (bigger) dataframe, their sizes will depend of the size of the smaller dataframe.

    Yields
    -------
    sub_df: pandas.DataFrame
        Part of the given dataframe.

    indexes: tuple of (int, int)
        Start and end indexes (row numbers) of the su_df in the given one.
    """
    iter_num_in_batch = 10000
    if smaller_df_length > 0.8 * iter_num_in_batch:  # slightly smaller than iter_num_in_batch or bigger
        iter_num_in_batch = smaller_df_length

    bigger_df_nrows_in_batch = iter_num_in_batch // smaller_df_length

    rownum = 0
    while rownum < bigger_df.shape[0]:
        next_rownum = rownum + bigger_df_nrows_in_batch
        yield bigger_df.iloc[rownum:next_rownum], (rownum, next_rownum)
        rownum = next_rownum
