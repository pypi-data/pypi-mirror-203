"""Main script to run Bayesian analysis of data from an Ecological Momentary Assessment (EMA) study.
This script should be used as a template,
to be copied and modified for any desired analysis.

*** Usage: four main steps, see also explicit template example below

*1: Set up an EmaFrame instance to define experiment and to select input data.
*2: Load a set of collected EMA data into an EmaDataSet instance
*3: Initialize and train an EmaModel instance for observed data.
*4: Display results and save figures and tables to a directory tree.


*** Version history:
* Version 0.9.5:
2023-03-07, ema_display.EmaDisplaySet include observed and model-predicted grade-count histograms
2023-03-01, timestamp_result if needed to avoid over-writing result files

* Version 0.9.3:
2022-08-14, Each ordinal rating scale may be unique or shared by more than one Attribute
2022-07-30, minor cleanup adapting to minor changes in package modules.

* Version 0.9.1:
2022-04-04, all result tables generated and saved as Pandas.DataFrame instances
2022-03-27, NAP and mean-grades results directly from raw data in ema_data.EmaDataSet
2022-03-21, using Pandas DataFrame format in EmaDataSet, allowing many input file formats

* Version 0.7.1:
2022-01-30, allow seed input to EmaModel.initialize for reproducible random results

* Version 0.7: minor update to include new calculation and display functions

* Version 0.6:
2021-12-08, allow user control of model restriction:
            restrict_attribute: sensory-variable location average forced -> 0.
            restrict_threshold: response-threshold median forced -> 0.

* Version 0.5:
2021-11-22, first functional version
"""
# -------- __main__ check to prevent multiprocessor sub-tasks to re-run this script
if __name__ == '__main__':
    import numpy as np
    from pathlib import Path
    import logging
    import datetime as dt
    import pickle

    from EmaCalc.ema_data import EmaFrame, EmaDataSet
    from EmaCalc.ema_model import EmaModel
    from EmaCalc.ema_display import EmaDisplaySet
    from EmaCalc import ema_logging, __version__
    from EmaCalc.ema_display_format import harmonize_ylim

    # ------------------------ Set up working directory and result logging:
    # timestamp_result = True  # Prevent over-writing result files
    timestamp_result = False  # Repeated runs will save results in same directory

    work_path = Path.home() / 'Documents' / 'EMA_sim'  # or whatever...
    data_path = work_path / 'data'  # to use simulation data generated by run_sim.py
    result_path = work_path / 'result'  # or whatever
    model_file = 'test_ema_model.pkl'  # name of saved model file (if saved)

    if timestamp_result:
        t = dt.datetime.now()
        result_path = result_path.with_name(result_path.name +
                                            f'-{t.year}-{t.month:02}-{t.day:02}-{t.hour:02}{t.minute}')

    ema_logging.setup(save_path=result_path,
                      log_file='run_ema_log.txt')  # to save the log file
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    logger.info(f'*** Running EmaCalc version {__version__} ***')

    # ------ 1: Define Experimental Framework: Situations, Attributes, and Grades

    # NOTE: This example uses data generated by template script run_sim.py
    # Edit as needed for any other EMA data source

    situations = {'Phase': ('',),  # only ONE Test phase with empty label
                  'HA': ('A', 'B'),  # Two Hearing-aid programs
                  'CoSS': [f'C{i}' for i in range(1, 8)],  # Seven CoSS categories
                  }  # Categorical variables
    # NOTE: First situation dimension is always phase, even if only ONE phase category.
    # User may set arbitrary phase_key label.
    # Dimension 'Phase' may be omitted, if only one phase category.
    # Category labels may be strings or integers, which can be used as part of file names.
    # If string labels are intended, avoid strings that can be interpreted as numbers,
    # because Pandas will read them as numbers by default.

    emf = EmaFrame.setup(situations=situations,
                         phase_key='Phase',
                         attributes={'Speech': ['Very Hard',
                                                'Hard',
                                                'Easy',
                                                'Very Easy',
                                                'Perfect'],
                                     'Comfort': ['Bad',
                                                 'Not Good',
                                                 'Not Bad',
                                                 'Good']}
                         )
    # NOTE: situations and attributes keys will be parts of result file names,
    # so they can include only characters allowed in file names.

    # NOTE: situations and attributes always analyzed as Categorical variables,
    # even if the categories / grades are defined by numeric labels.
    # The rank order of attribute grades is defined by the order as listed here,
    # NOT by, e.g., alphabetical or numerical order of the grade labels.

    # NOTE: if EQUAL grades are used for more than one attribute,
    # the model still assumes separate rating scales for each attribute.
    # However, if grade sequences are IDENTICAL objects for more than one attribute,
    # the model uses the SAME rating scale for those attributes.
    #
    # Example:
    # common_ordinal_scale = ['Very Hard',
    #                         'Hard',
    #                         'Easy',
    #                         'Very Easy',
    #                         'Perfect']
    # emf = EmaFrame.setup(situations=situations,
    #                      phase_key='Phase',
    #                      attributes={'Speech': common_ordinal_scale,
    #                                  'Comfort': common_ordinal_scale}  # SAME scale for both attributes
    #                      )

    # In either case, response thresholds are always estimated separately for each participant.

    # ------ 2: Load data from previously saved file(s):

    # NOTE: if 'grouping' is defined, group directory names must match given labels,
    # as exemplified in module ema_data doc-string.
    # With template example: data_path / 'Age_old' is top of directory tree with data files.
    # If several 'grouping' factors are defined, the directory tree structure must match the factors.
    # If no grouping is defined: data_path is top of directory tree with all data files

    ds = EmaDataSet.load(emf, data_path,
                         # fmt='csv',  # None: try any file format
                         # grouping=None,  # default: include all participants as ONE unnamed group
                         # grouping={'Age': ('old',),  # analyze only group Age=old
                         #           },
                         grouping={'Age': ('young','old')},  # analyze both Age groups separately
                         # participant='file',  # default
                         # participant='sheet',   # participant ID defined in xlsx sheet title, OR
                         # participant='SubjectID',  # participant IDs defined in column 'SubjectID'
                         # rename_cols={'Hearing Aid: 'HA'},  # dict with (file, new) column names
                         # header=0,  # first table row shows column headers
                         # converters={'Comfort': _recode_comfort, ...},  # user-defined mapping(s)
                         # ... any additional arguments to Pandas read_xxx function, if needed
                         )
    logger.info(f'Using data ds=\n{ds}')

    # ----------------- (Optional) show rating counts for all participants
    for attr in emf.attribute_dtypes.keys():
        a_count = ds.attribute_grade_count(attr, groupby='HA')
        logger.info(str(attr) + '_grade_count:\n' + a_count.to_string())
        logger.info(str(attr) + ': sum grade_count= ' + f'{np.sum(a_count.to_numpy())}')
        # a_count.save(result_path / (str(attr) + '_grades.csv'))

    # ----------------- (Optional) show mean grades and NAP results for all participants
    mean_grades = ds.attribute_grade_mean(groupby=('HA', 'CoSS'))
    mean_grades.save(result_path / 'Attribute_mean_grades.txt', float_format='%.2f')
    # mean_grades.save(result_path / 'Attribute_mean_grades.csv',
    #                  float_format='%.4f')  # if needed for other analysis
    logger.info(f'Attribute mean grades saved in {result_path}'
                + '\nCAUTION: Mean values presume METRIC data, but attribute grades are only ORDINAL!')

    # nap = ds.nap_table('HA', nap_cat=['A', 'B'], groupby=('CoSS',), p=0.95)  # grouped results
    nap = ds.nap_table('HA', nap_cat=['A', 'B'], p=0.95)  # aggregated across other situation dimensions
    nap.save(result_path / 'NAP.txt', float_format='%.2f')  # pretty-formatted by Pandas
    # nap.save(result_path / 'NAP.tex', float_format='%.2f')  # for import to LaTeX doc.
    # nap.save(result_path / 'NAP.csv', sep='\t')  # tab-delimited text, for input to other program
    logger.info(f'NAP results saved in {result_path}')

    # ------ 3: Learn Analysis Model from loaded data set:

    # Model ordinal-regression effects of Situations on each Attribute:

    # regression_effects = ['HA',     # main linear regression effect only
    #                       'CoSS',   # main linear regression effect only
    #                       # 'Phase',  # if there are several phase categories
    #                       ]

    regression_effects = [('HA', 'CoSS')  # joint effects, main AND interaction
                          # 'Phase',  # if there are several phase categories
                          ]

    # NOTE: A regression_effects element may include any combination of situation dimensions, BUT
    # including ALL interactions -> many model parameters,
    # possibly -> less precise estimation for each parameter.

    # In this example: ['HA', 'CoSS'] -> 2 + (7 - 1) = 8 regression-effect parameters
    #                ['CoSS', 'HA'] -> 7 + (2 - 1) = 8 regression-effect parameters
    #                [('HA', 'CoSS')] -> 2 * 7 = 14 regression-effect parameters

    emm = EmaModel.initialize(ds,
                              effects=regression_effects,
                              max_n_comp=10,
                              restrict_attribute=False,  # default
                              restrict_threshold=True,  # default
                              # seed=12345  # ONLY if reproducible results are required
                              )
    # max_n_comp = max number of mixture components in population model
    # restrict_attribute=True -> force attribute mean location at zero
    # restrict_threshold=True -> force mid-scale response threshold at zero
    # for each respondent and each sample of each attribute

    ll = emm.learn(max_hours=1., max_minutes=0.)
    logger.info('ll= ' + np.array2string(np.array(ll),
                                         precision=5))
    emm.prune()  # keep only active mixture components.
    # NOTE: If the number of components is not reduced,
    # it might be a good idea to re-run with larger initial max_n_comp,
    # but max_n_comp always <= half number of participants

    # -------- Save learned EmaModel (optional):
    with (work_path / model_file).open('wb') as f:
        pickle.dump(emm, f)
        logger.info('Model pickle-dumped as ' + f.name)

    # ------ 4: Generate result displays:

    # -------- Re-load learned EmaModel (optional, if saved):
    # with (work_path / model_file).open('rb') as f:
    #     emm = pickle.load(f)
    # -------------------------------------------------
    emd = EmaDisplaySet.show(emm,
                             situations=['CoSS',  # CoSS probabilities, aggregated across HA
                                         ('CoSS', 'HA'),  # CoSS probabilities, conditional on HA
                                         ('HA', 'CoSS'),  # HA probabilities, conditional on CoSS
                                         ],
                             attributes=[('Speech', 'CoSS'),  # Speech, main effect of CoSS
                                         ('Speech', 'HA'),    # Speech, main effect of HA
                                         ('Speech', ('CoSS', 'HA')),  # joint effect of both
                                         ('Comfort', ('CoSS', 'HA'))],  # joint effect of both
                             grade_counts=['Speech',
                                           ('Speech', 'HA'),
                                           ('Comfort', 'HA')],  # *** version 0.9.5 ***
                             random_individual=True,  # random individual in population
                             population_mean=True,  # population mean
                             participants=False,  # individual results: True -> MANY plots and tables
                             grade_thresholds=True,  # response thresholds in attribute plots
                             percentiles=[2.5, 25, 50, 75, 97.5],  # in profile plots and tables
                             credibility_limit=0.7,  # minimum credibility in difference tables
                             # n_samples=10000,  # default=1000, for percentile calculations
                             mpl_params={'figure.max_open_warning': 0,
                                         'axes.labelsize': 'x-large'},  # -> matplotlib.rcParam
                             # mpl_style='my_style_sheet',
                             # ... any other ema_display.FMT or ema_display_format.FMT settings
                             )
    # NOTE: joint (=interaction) effects are correct only if included in model regression_effects

    # ------------------------------- (optionally) edit display elements, if desired
    for g_disp in emd.groups.values():
        harmonize_ylim([g_disp.population_mean.attributes[('Speech', ('CoSS', 'HA'))].plot.ax,
                        g_disp.random_individual.attributes[('Speech', ('CoSS', 'HA'))].plot.ax,
                        g_disp.population_mean.attributes[('Comfort', ('CoSS', 'HA'))].plot.ax,
                        g_disp.random_individual.attributes[('Comfort', ('CoSS', 'HA'))].plot.ax
                        ])
        harmonize_ylim([g_disp.population_mean.situations[('CoSS', 'HA')].plot.ax,
                        g_disp.random_individual.situations[('CoSS', 'HA')].plot.ax,
                        ])

    # -> matching y-axis limits: nice for plots to be shown side by side

    # ------------------------------- save all result displays
    emd.save(result_path,
             figure_format='pdf',   # or any other format allowed by Matplotlib
             table_format='txt',    # or csv, tex, xlsx, or other allowed by ema_file and Pandas
                                    # NOTE: tex requires jinja2 to be installed manually
             float_format='%.2f',   # any other parameters for Pandas table-writer function
             )
    # (optionally) save in other format(s), too:
    # emd.save(result_path,
    #          table_format='csv',  # for input to other package
    #          float_format='%.4f',  # any other parameters for Pandas table-writer function
    #          # sep='\t'  # -> tab-delimited
    #          )

    logging.info(f'All results saved in {result_path}')

    logging.shutdown()
